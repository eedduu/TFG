\section{Introducción}

Las redes neuronales profundas han revolucionado el campo de la inteligencia artificial, permitiendo avances significativos en varios ámbitos como el procesamiento del lenguaje natural, reconocimiento de voz o visión por computador. Su capacidad para extraer patrones y representaciones complejas de grandes conjuntos de datos con un coste computacional muy eficiente en comparación con otras técnicas las ha convertido en la piedra angular de los sistemas modernos de aprendizaje automático. En visión por computador, las \textit{Convolutional Neural Networks} (ConvNets) o redes convolucionales se han erigido como la familia de modelos que consigue un rendimiento del estado del arte \cite{GoodFellowBook}.

Las ConvNets son un tipo de red neuronal que procesan datos en forma de grid. Se caracterizan porque tienen al menos una capa donde usan convoluciones en lugar de matrices generales de multiplicación. La convolución es un tipo de operación lineal que permite capturar representaciones espaciales aplicando un filtro a la entrada, detectando primero características de bajo nivel como bordes y texturas y aumentando el nivel de complejidad de la representación en las capas sucesivas \cite{GoodFellowBook}.

Las \textit{Residual Nets} (ResNets) son una subfamilia de ConvNets que atajan el problema del desvanecimiento y explosión de gradiente (ver sección \ref{sec:desvyexpl}). Cuantas más capas tiene una red neuronal profunda más probable es que sufra este problema, ya que se arrastran más operaciones. Las ResNet crean bloques residuales donde se crea un atajo entre el inicio y el final del bloque, sumando la identidad al final, lo que permite que el gradiente fluya de manera más efectiva durante el proceso de \textit{backpropagation} \cite{ResNets}.

El gradiente descendente es un algoritmo de aprendizaje que permite entrenar este tipo de modelos de forma eficiente, robusta y con mucho rigor teórico. Sin embargo, como ya se ha comentado anteriormente, tiene algunas limitaciones, las cuales se incrementan cuantas más capas y parámetros tiene el modelo que entrenamos. Además de desarrollar mejoras en él con los optimizadores, se buscan nuevos algoritmos de aprendizaje que eviten los problemas que presenta este algoritmo.

Una de estas aproximaciones son las técnicas metaheuristicas: estrategias de optimización basadas normalmente en componentes bio-inspirados, flexibles y adaptables a gran variedad de problemas. Ofrecen una solución cercana a la óptima en un tiempo razonable en muchos problemas cuya solución óptima es computacionalmente inalcanzable, como en problemas NP-Difícil. Son técnicas iterativas que no ofrecen una garantía teórica de hallar una buena solución, pero a través de restricciones en el algoritmo se espera que lo hagan \cite{MHDef}.

Los más conocidos son los algoritmos evolutivos, inspirados en la evolución genética. En ellos, se genera una población aleatoria y, de forma iterativa, se seleccionan los mejores individuos, se recombinan entre ellos, se mutan para obtener más diversidad genética y se reemplazan los nuevos individuos en la población. Se pueden introducir modificaciones como criterios elitistas, en los que, por ejemplo, reemplazaríamos la población antigua solo si fuera peor que la nueva. Los algoritmos evolutivos basados en \textit{Differential Evolution} (DE) se especializan en optimización con parámetros reales y enfatizan la mutación, utilizando el operador de cruce a posteriori. Alcanzan el rendimiento de estado del arte en optimización continua. \cite{MHoverview}.

Los algoritmos meméticos son una hibridación de las técnicas metaheurísticas con algoritmos de búsqueda local, que añaden el uso de información específica del problema. Combinan así la capacidad exploradora del espacio de soluciones que tienen los algoritmos evolutivos con la capacidad explotadora de la búsqueda local. El optimizador local se considera una etapa más dentro del proceso evolutivo y debe incluirse en él \cite{MHDef}.



\subsection{Motivación}
\label{sec:motinfo}

El ajuste de pesos de un modelo es una de las partes más importantes en su desarrollo y por eso necesitamos técnicas que ofrezcan cada vez mejores resultados y mayor eficiencia. No se trata de un problema sencillo, ya que el número de parámetros de los modelos, es decir, la dimensión del problema de optimización, tiende a aumentar rápidamente. Aunque el gradiente descendente sea una estrategia muy buena, hemos visto sus limitaciones, lo que nos incita a intentar encontrar otros algoritmos de aprendizaje. Las metaheurísticas toman cada vez un papel más protagonista en la optimización de problemas complejos y de grandes dimensiones a un bajo coste, lo que las sitúa como un posible sustituto.

Para la realización del presente TFG nos basaremos en el reciente artículo de Daniel Molina y Francisco Herrera (entre otros) \cite{MHtrainingClase}, donde se analiza el papel actual de las metaheurísticas tanto en el entrenamiento de los modelos como en la selección de los hiperparámetros y la topología de la red. Nos centraremos únicamente en el primer caso. En él se realiza también un experimento práctico comparativo entre Adam, un optimizador basado en el gradiente descendente, y diferentes versiones de SHADE-ILS, una técnica metaheurística basada en DE que hace uso de búsqueda local (algoritmo memético) que ofrece actualmente los mejores resultados en el entrenamiento de modelos a través de metaheurísticas.

En dicha publicación se realiza una revisión de la literatura en lo referente a las técnicas metaheurísticas para el entrenamiento de modelos, analizando los resultados de los artículos más recientes y criticando de manera general la falta de rigor metodológico en la mayoría de ellos. Además, señala que no resulta fácil realizar una comparación totalmente objetiva entre dos ténicas tan distintas como el gradiente descendente y los algoritmos bio-inspirados. Estas son algunas de las principales carencias en la literatura mencionadas, junto a cómo las afrontaremos:

\begin{itemize}

\item Falta de homogeneidad en los conjuntos de datos usados y las tareas a resolver, lo que no permite una comparación objetiva entre diferentes experimentos. Usaremos, cuando proceda, los mismos conjuntos de datos con las mismas condiciones experimentales.

\item Uso de modelos con escalas no realistas para probar algoritmos bio-inspirados, que normalmente constan de unos pocos miles de parámetros. En el presente TFG, la gama de modelos en función de sus parámetros irá desde los 2 mil hasta rondar los 1.5 millones de parámetros, rango elegido en concordancia con el punto anterior.

\item Malas prácticas metodológicas para la comparación de algoritmos; por ejemplo, de manera generalizada, se suelen comparar varias técnicas metaheurísticas entre sí, sin compararlas con el algoritmo de gradiente descendente. En la experimentación, usaremos varias técnicas metaheurísticas y varios optimizadores de gradiente descendente.

\item Aunque es bien sabido que los algoritmos metaheurísticos requieren muchos más recursos computacionales que los clásicos, no se realizan análisis de complejidad, de modo que no se establece una equivalencia o comparación objetiva en el rendimiento. En la experimentación, asignamos deliberadamente más recursos al entrenamiento con metaheurísticas y establecemos una equivalencia de manera que podamos realizar más adelante un análisis de la complejidad computacional.
\end{itemize}

Cabe destacar además que la práctica totalidad de técnicas metaheurísticas se prueban con ConvNets y \textit{Recurrent Neural Networks} \cite{divedeeplearning}, mientras que las hibridaciones meméticas de estas técnicas, usando el gradiente descendente como búsqueda local, se estudian mayoritariamente en ConvNets.



\subsection{Objetivos}\label{sec:objinf}

Aunque la actual superioridad del entrenamiento de modelos de aprendizaje profundo entrenados con el algoritmo del gradiente descendente, en términos de rendimiento y coste computacional, se evidencia en la literatura, las carencias que hemos visto en el punto anterior hacen necesaria más experimentación con el rigor y las condiciones adecuadas. Aunque no será planteado como una cuestión a responder, un objetivo subyacente del presente TFG es mantener el rigor experimental que en muchas ocasiones falta en la literatura con algoritmos bio-inspirados, de manera que tomaremos el artículo mencionado anteriormente como referencia para establecer un entorno y unas condiciones similares para que los resultados puedan ser comparables con otros externos.


De forma conceptual dividiremos la experimentación en dos partes, siendo común a ambas los algoritmos de aprendizaje: Adam, \textit{Nesterov Accelerated Gradient} (NAG) y RMSProp en el caso de las técnicas clásicas, y SHADE, SHADE-ILS, SHADE-GD y SHADE-ILS-GD en el caso de las metaheurísticas. Destacamos que estas dos últimas técnicas son propuestas propias y no se han encontrado experimentos con ellas en la literatura. Aclaramos que, a no ser que se especifique explícitamente, cuando nos referimos a técnicas metaheurísticas englobamos las técnicas con y sin búsqueda local. En la primera parte, afrontaremos cuatro tareas con conjuntos de datos tabulares, entrenando para cada tarea varios modelos \textit{Multi-Layered Perceptron} (MLP) de diverso número de capas y de parámetros con cada una de las técnicas antes mencionadas. En la segunda realizaremos tres tareas de reconocimiento de imágenes usadas en \cite{MHtrainingClase} y el mismo entorno experimental, entrenando para cada tarea tres modelos de ConvNets de distinto número de capas y parámetros, con las técnicas antes mencionadas. De esta manera, definimos las conclusiones que queremos obtener de la experimentación:

\begin{itemize}

%\item \textit{P1. ¿Cuál es el rendimiento de las técnicas metaheurísticas en los modelos MLP?}. Como la literatura no es extensa en este ámbito, queremos comprobar si existe alguna diferencia al usar técnicas metaheurísticas para entrenar MLP y ConvNets, comparando los resultados de éstas técnicas con las del gradiente descendente en cada familia de modelos.

\item \textit{P1. Análisis del rendimiento de las técnicas metaheurísticas}. Aunque conocemos la superioridad del gradiente descendente, queremos analizar de manera minuciosa cómo influyen las siguientes tres variantes en el rendimiento de estas técnicas en comparación con él:
	
	\begin{enumerate}
		\item Complejidad de la tarea.
		
		\item Tamaño del modelo.
		
		\item Tamaño del conjunto de datos.
	\end{enumerate}

\item \textit{P2. Análisis de la complejidad computacional de las metaheurísticas}. En base a los tres criterios anteriores.

\item \textit{P3. ¿Existe diferencia para tareas de clasificación y regresión?}. Para una comparación objetiva, analizaremos los resultados de las tareas asociadas a los cuatro conjuntos de datos tabulares, donde dos son tareas de clasificación y dos de regresión, con la misma dificultad en pares.



\item \textit{P4. Propuesta de técnicas híbridas}. Proponemos dos algoritmos meméticos: SHADE-GD y SHADE-ILS-GD, añadiendo una búsqueda local a través de un optimizador de gradiente descendente a las técnicas originales. Analizaremos el rendimiento de cada una en base a su versión sin hibridar.

\end{itemize}

Como aclaración, cuando comparemos dos técnicas lo haremos en base a estos tres criterios:

\begin{itemize}
	\item Minimización de la función de pérdida.
	
	\item Generalización del modelo entrenado.
	
	\item Tiempo requerido para el entrenamiento.
\end{itemize}	
	
Destacar que podemos responder a las preguntas P3 y P4 gracias a que sobre cada tarea entrenamos un total de $N_{modelos} \times N_{tecnicas}$ veces, lo que equivaldría a 28 modelos entrenados en cada conjunto de datos en la primera parte de la experimentación y 21 modelos en la segunda.