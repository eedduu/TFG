\section{Introducción}

Las redes neuronales profundas han revolucionado el campo de la inteligencia artificial, permitiendo avances significativos en varios campos como el procesamiento del lenguaje natural, reconocimiento de voz o visión por computador. Su capacidad para extraer patrones y representaciones complejas de grandes datasets y a un coste computacional muy eficiente en comparación con otras técnicas las han convertido en piedra angular de los sistemas modernos de aprendizaje automático. En el campo de la visión por computador, las \textit{Convolutional Neural Networks} (ConvNets) o redes convolucionales se han erigido como la familia de modelos que consigue un rendimiento del estado del arte \cite{GoodFellowBook}.

Las ConvNets son un tipo de red neuronal que procesan datos en forma de grid. Se caracterizan porque tienen al menos una capa donde usan la operación de convolución en lugar de una matriz general de multiplicación. La convolución es un tipo de operación lineal que permite capturar representaciones espaciales aplicando un filtro a la entrada, detectando primero características de bajo nivel como bordes y texturas y aumentando el nivel de complejidad de la representación en las capas sucesivas \cite{GoodFellowBook}.

Las \textit{Residual Nets} (ResNets) son una subfamilia de ConvNets que atajan el problema del desvanecimiento y explosión de gradiente (ver sección \ref{sec:desvyexpl}). Cuantas más capas tiene una red neuronal profunda más probable es que sufra este problema, ya que se arrastran más operaciones. Las ResNet crean bloques residuales donde se crea un atajo entre el inicio y el final del bloque en el que se suma la identidad al final del bloque, provocando que el gradiente pueda fluir de manera más efectiva durante el proceso de BP \cite{ResNets}.

El gradiente descendente es un algoritmo de aprendizaje que nos permite entrenar este tipo de modelos de forma eficiente, robusta, y con mucho rigor teórico. Sin embargo como ya se ha comentado en la parte anterior tiene algunas limitaciones, y estas se ven incrementadas cuantas más capas y más parámetros tiene el modelo que entrenamos. A parte de desarrollar mejoras en él con los optimizadores, se buscan nuevos algoritmos de aprendizaje que permitan evitar los problemas que presenta el gradiente descendente.

Una de estas aproximaciones son las técnicas metaheuristicas: estrategias de optimización basadas normalmente en componentes bio-inspirados y que son flexibles y adaptables a gran variedad de problemas. Ofrecen una solución cercana a la óptima en un tiempo razonable en muchos problemas cuya solución óptima es computacionalmente inalcanzable, como en problemas NP-Hard. Son técnicas iterativas que no ofrecen una garantía teórica de hallar una buena solución, pero a través de restricciones en el algoritmo se espera que lo haga \cite{MHtrainingClase}.

Los más conocidos son los algoritmos evolutivos inspirados en la evolución genética. En ellos se genera una población aleatoria e iterativamente se realizan los procesos de: seleccionar los mejores individuos, recombinarlos entre ellos, mutarlos para obtener más diversidad genética, y reemplazar los nuevos individuos en la población. Se pueden introducir modificaciones como criterios elitistas, en los que por ejemplo reemplazaríamos la población antigua sólo si fuera peor que la nueva. Los algoritmos evolutivos basados en \textit{Differential Evolution} (DE) se especializan en optimización con parámetros reales y enfatizan la mutación, utilizando el operador de cruce a posteriori de ella. Alcanzan el rendimiento de estado del arte en optimización continua \cite{MHoverview}.

Los algoritmos meméticos son una hibridación de las técnicas metaheurísticas con algoritmos de búsqueda local, que añaden el uso de información específica del problema. Combinan así la capacidad exploradora del espacio de soluciones que tienen los algoritmos evolutivos con la capacidad explotadora de la búsqueda local. El optimizador local se considera una etapa más dentro del proceso evolutivo y debe incluirse en él.



\subsection{Motivación}
\label{sec:motinfo}

El ajuste de pesos de un modelo es una de las partes más importantes en su desarrollo y por eso necesitamos de técnicas que nos ofrezcan cada vez mejores resultados a la vez que mayor eficiencia. No se trata de un problema sencillo ya que el número de parámetros de los modelos, es decir la dimensión del problema de optimización, tiene una tendencia que va rápidamente en aumento. Aunque el gradiente descente sea una estrategia muy buena hemos visto sus limitaciones, que nos incitan a intentar encontrar otras estrategias de aprendizaje. Las metaheurísticas toman cada vez un papel más protagonista en la optimización de problemas complejos y de grandes dimensiones a un bajo coste, lo que las sitúa como un posible sustituto.

Para la realización del presente TFG nos basaremos en el reciente paper de Daniel Molina y Francisco Herrera \cite{MHtrainingClase} donde se analiza el papel que juegan actualmente las metaheurísticas tanto en el en entrenamiento de los modelos, como en la selección de los hiperparámetros y de la topología de la red. Nos centraremos únicamente en el primer caso. En él se realiza también un experimento práctico comparativo entre Adam, un optimizador basado en el gradiente descendente, y diferentes versiones de SHADE-ILS, una técnica metaheurística basada en DE que hace uso de búsqueda local (técnica memética) que ofrece los mejores resultados actualmente en el entrenamiento de modelos a través de metaheurísticas.

En dicha publicación se realiza una revisión de la literatura en lo referente a las técnicas metaheurísticas para el entrenamiento de modelos, analizando los resultados de los paper más recientes y criticando de manera general la falta de rigor metodológico en la mayoría de ellos, sumado a que no resulta fácil realizar una comparación totalmente objetiva entre dos ténicas tan distintas como el gradiente descendente y los algoritmos bio-inspirados. Estas son algunas de las principales carencias en la literatura mencionadas en dicho paper, junto a cómo las afrontaremos:

\begin{itemize}

\item Falta de homogeneidad en los \textit{datasets} usados y las tareas a resolver, lo que no permite una comparación objetiva entre diferentes experimentos. Usaremos cuando proceda los mismos \textit{datasets} con las mismas condiciones experimentales.

\item Se usan escalas de modelos no realistas para probar algoritmos bio-inspirados, que normalmente constan de unos pocos miles de parámetros. En el presente TFG la gama de modelos en función de sus parámetros irá desde los 2 mil parámetros hasta rondar los 1.5M de parámetros, rango elegido en concordancia con el punto anterior.

\item Malas prácticas metodológicas para la comparación de algoritmos, por ejemplo, de manera generalizada se suelen comparar varias técnicas metaheurísticas entre ellas, sin que se comparen con el algoritmo de gradiente descendente. En la experimentación usaremos varias técnicas metaheurísticas y varios optimizadores de gradiente descendente.

\item Aunque es bien sabido que los algoritmos metaheurísticos requieren de muchos más recursos computacionales que los clásicos, no se realizan análisis de complejidad, de manera que no se establece una equivalencia o comparación objetiva en el rendimiento. En la experimentación asignamos deliberadamente más recursos al entrenamiento con metaheurísticas, y establecemos una equivalencia de manera que podamos realizar más adelante una comparación de la complejidad.
\end{itemize}

Cabe destacar además que la práctica totalidad de técnicas metaheurísticas se prueban con ConvNets y RNNs, mientras que las hibridaciones de estas técnicas con el gradiente descendente se estudian mayoritariamente en ConvNets.



\subsection{Objetivos}

Aunque la actual superioridad del entrenamiento de modelos de aprendizaje profundo con el algoritmo del gradiente descendente, en términos de resultados y coste computacional, se evidencie en la literatura, las carencias en la misma que hemos visto en el punto anterior hacen necesaria más experimentación en las condiciones y con el rigor adecuados. El objetivo de este TFG es ofrecer una batería experimental amplia, que permita comparar de manera objetiva las técnicas clásicas, las metaheurísticas y su hibridación, y que además pueda ser comparada de manera objetiva con otros experimentos.


De forma conceptual dividiremos la experimentación en dos partes, siendo común a las dos las técnicas usadas para el entrenamiento de modelos, que son: Adam, NAG y RMSProp en el caso de las técnicas clásicas y SHADE, SHADE-ILS, SHADE-GD y SHADE-ILS-GD en el caso de las metaheurísticas. Destacamos que estas dos últimas técnicas son propuesta propia, y no se han encontrado experimentos con ellas en la literatura. Aclarar que, a no ser que se especifique explícitamente, cuando nos referimos a técnicas metaheurísticas englobamos las técnicas estándar y las hibridadas. En la primera afrontaremos cuatro tareas con datasets tabulares, entrenando para cada tarea varios modelos MLP de diverso número de capas y de parámetros con cada una de las técnicas antes mencionadas. En la segunda tendremos tres tareas de reconocimiento de imágenes usados en \cite[MHtrainingClase] y el mismo entorno experimental, entrenando para cada tarea tres modelos de ConvNets de distinto número de capas y parámetros, con las técnicas antes mencionadas. De esta manera, definimos las conclusiones que queremos obtener de la experimentación:

\begin{itemize}

\item \textit{P1. ¿Cuál es el rendimiento de las técnicas metaheurísticas en los modelos MLP?}. Como la literatura no es extensa en este ámbito, queremos comprobar si existe alguna diferencia al usar técnicas metaheurísticas para entrenar MLP y ConvNets, comparando los resultados de éstas técnicas con las del gradiente descendente en cada familia de modelos.

\item \textit{P2. ¿Existe diferencia para tareas de clasificación y regresión?}. Para una comparación objetiva, compararemos los resultados de las tareas asociadas a los cuatro \textit{datasets} tabulares, donde dos son tareas de clasificación y dos de regresión.

\item \textit{P3. Análisis del rendimiento de las técnicas metaheurísticas}. Aunque conocemos la superioridad del gradiente descendente, queremos analizar de manera minuciosa cómo influyen las siguientes tres variantes en el rendimiento de estas técnicas en comparación con él:
	
	\begin{enumerate}
		\item Complejidad de la tarea
		
		\item Tamaño del modelo
		
		\item Tamaño del \textit{dataset}
	\end{enumerate}

\item \textit{P4. Análisis de la complejidad computacional de las metaheurísticas}. En comparación con el gradiente descendente y a partir de las tres variantes anteriores, en base al concepto de época.

\item \textit{P5. Comparativa de las técnicas híbridas propuestas}. Analizamos la hibridación de dos de las técnicas que obtienen mejores resultados en el entrenamiento de modelos con el gradiente descendente. Analizando si mejoran y en qué lo hacen a sus versiones sin gradiente descendente.

\end{itemize}

Como aclaración, cuando comparemos dos técnicas lo haremos en base a estos tres criterios:

\begin{itemize}
	\item Minimización de la función de pérdida.
	
	\item Generalización del modelo entrenado.
	
	\item Tiempo requerido para el entrenamiento.
\end{itemize}	
	
Destacar que podemos responder a las preguntas P3 y P4 gracias a que sobre cada tarea entrenamos un total de $N_{modelos} \times N_{tecnicas}$ veces, lo que equivaldría a 28 modelos entrenados para cada tarea en la primera parte de la experimentación y 21 modelos por tarea en la segunda.