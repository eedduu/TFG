{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlWgCsDo5C5k"
   },
   "source": [
    "#Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-09-24T19:59:16.811658Z",
     "iopub.status.busy": "2024-09-24T19:59:16.810997Z",
     "iopub.status.idle": "2024-09-24T19:59:37.307871Z",
     "shell.execute_reply": "2024-09-24T19:59:37.303967Z",
     "shell.execute_reply.started": "2024-09-24T19:59:16.811615Z"
    },
    "id": "UwJO5w4X5Bl7",
    "outputId": "68f45257-7067-427b-daa4-932c2fb0e013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai\n",
      "  Downloading fastai-2.7.17-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai) (23.3.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastai) (23.2)\n",
      "Collecting fastdownload<2,>=0.0.5 (from fastai)\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting fastcore<1.8,>=1.5.29 (from fastai)\n",
      "  Downloading fastcore-1.7.9-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.11/dist-packages (from fastai) (0.16.1+cu121)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from fastai) (3.7.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from fastai) (2.2.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from fastai) (2.31.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from fastai) (5.4.1)\n",
      "Collecting fastprogress>=0.2.4 (from fastai)\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from fastai) (9.5.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from fastai) (1.3.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from fastai) (1.11.2)\n",
      "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.11/dist-packages (from fastai) (3.6.1)\n",
      "Requirement already satisfied: torch<2.5,>=1.10 in /usr/local/lib/python3.11/dist-packages (from fastai) (2.1.1+cu121)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (0.11.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (1.26.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (1.10.14)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (69.0.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<4->fastai) (3.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->fastai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->fastai) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->fastai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->fastai) (2020.6.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.5,>=1.10->fastai) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch<2.5,>=1.10->fastai) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.5,>=1.10->fastai) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.5,>=1.10->fastai) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.5,>=1.10->fastai) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.5,>=1.10->fastai) (2.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->fastai) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->fastai) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->fastai) (2023.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->fastai) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->fastai) (3.2.0)\n",
      "Requirement already satisfied: pathlib-abc==0.1.1 in /usr/local/lib/python3.11/dist-packages (from pathy>=0.10.0->spacy<4->fastai) (0.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4->fastai) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<4->fastai) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.5,>=1.10->fastai) (1.3.0)\n",
      "Downloading fastai-2.7.17-py3-none-any.whl (234 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.5/234.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastcore-1.7.9-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.1/80.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: fastprogress, fastcore, fastdownload, fastai\n",
      "Successfully installed fastai-2.7.17 fastcore-1.7.9 fastdownload-0.0.7 fastprogress-1.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting nbdev\n",
      "  Downloading nbdev-2.3.31-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from nbdev) (23.2)\n",
      "Requirement already satisfied: fastcore>=1.5.27 in /usr/local/lib/python3.11/dist-packages (from nbdev) (1.7.9)\n",
      "Collecting execnb>=0.1.4 (from nbdev)\n",
      "  Downloading execnb-0.1.6-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from nbdev) (1.6.3)\n",
      "Collecting ghapi>=1.0.3 (from nbdev)\n",
      "  Downloading ghapi-1.0.6-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting watchdog (from nbdev)\n",
      "  Downloading watchdog-5.0.2-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: asttokens in /usr/local/lib/python3.11/dist-packages (from nbdev) (2.4.1)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from nbdev) (5.4.1)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from execnb>=0.1.4->nbdev) (8.20.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from asttokens->nbdev) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->nbdev) (0.35.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->execnb>=0.1.4->nbdev) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->execnb>=0.1.4->nbdev) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->execnb>=0.1.4->nbdev) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.11/dist-packages (from ipython->execnb>=0.1.4->nbdev) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from ipython->execnb>=0.1.4->nbdev) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.11/dist-packages (from ipython->execnb>=0.1.4->nbdev) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.11/dist-packages (from ipython->execnb>=0.1.4->nbdev) (5.14.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->execnb>=0.1.4->nbdev) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->execnb>=0.1.4->nbdev) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->execnb>=0.1.4->nbdev) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->execnb>=0.1.4->nbdev) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from stack-data->ipython->execnb>=0.1.4->nbdev) (2.0.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.11/dist-packages (from stack-data->ipython->execnb>=0.1.4->nbdev) (0.2.2)\n",
      "Downloading nbdev-2.3.31-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.4/67.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading execnb-0.1.6-py3-none-any.whl (14 kB)\n",
      "Downloading ghapi-1.0.6-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchdog-5.0.2-py3-none-manylinux2014_x86_64.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: watchdog, ghapi, execnb, nbdev\n",
      "Successfully installed execnb-0.1.6 ghapi-1.0.6 nbdev-2.3.31 watchdog-5.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.0)\n",
      "Collecting certifi>=2020.12.5 (from ucimlrepo)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.0.0->ucimlrepo) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: certifi, ucimlrepo\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2020.6.20\n",
      "    Uninstalling certifi-2020.6.20:\n",
      "      Successfully uninstalled certifi-2020.6.20\n",
      "Successfully installed certifi-2024.8.30 ucimlrepo-0.0.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyade'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     34\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/notebooks/utilstfg.py\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutilstfg\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutilsTFG\u001b[39;00m\n",
      "File \u001b[0;32m/notebooks/utilstfg.py:761\u001b[0m\n\u001b[1;32m    758\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mx, result\u001b[38;5;241m.\u001b[39mfun, result\u001b[38;5;241m.\u001b[39mnfev, result\u001b[38;5;241m.\u001b[39mnjev\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable\n\u001b[0;32m--> 761\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyade\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyade\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshade\u001b[39;00m\n\u001b[1;32m    765\u001b[0m algorithm \u001b[38;5;241m=\u001b[39m pyade\u001b[38;5;241m.\u001b[39mshade\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyade'"
     ]
    }
   ],
   "source": [
    "#Install dependencies\n",
    "!pip install fastai\n",
    "!pip install nbdev\n",
    "!pip install ucimlrepo\n",
    "\n",
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastai\n",
    "from fastai.tabular.all import *\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import copy\n",
    "import time\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchvision\n",
    "\n",
    "#Connect to drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "\n",
    "#Convert and import personalised library\n",
    "#!jupyter nbconvert --to python /content/drive/MyDrive/Colab\\ Notebooks/utilsTFG.ipynb --output utilsTFG.py\n",
    "#!cp /content/drive/MyDrive/Colab\\ Notebooks/utilsTFG.py .\n",
    "import sys\n",
    "sys.path.append('/notebooks/utilstfg.py')\n",
    "import utilstfg as utilsTFG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.308117Z",
     "iopub.status.idle": "2024-09-24T19:59:37.309080Z",
     "shell.execute_reply": "2024-09-24T19:59:37.309080Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.309080Z"
    },
    "id": "U6arDC3clxEh",
    "outputId": "3050b25c-f052-4379-bcf3-56a01be86581"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# Set seed for fastai\n",
    "fastai.torch_core.set_seed(42)\n",
    "\n",
    "# Set seed for torch\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Set seed for numpy\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3A_JuZUuznV"
   },
   "source": [
    "### Datos y modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.310060Z",
     "iopub.status.idle": "2024-09-24T19:59:37.310370Z",
     "shell.execute_reply": "2024-09-24T19:59:37.310245Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.310230Z"
    },
    "id": "SSxcXskYTLo5",
    "outputId": "6480a6b6-b925-4012-fe2c-656c63f7b6e6"
   },
   "outputs": [],
   "source": [
    "#Load the MNIST dataset\n",
    "dataset='FMNIST'\n",
    "plot_dataset='FMNIST'\n",
    "\n",
    "\n",
    "#Import the MNIST Dataset\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    transforms.Resize([32,32])\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "# Reduce training and test datasets\n",
    "reduced_train_dataset = utilsTFG.reduce_dataset(train_dataset, 10000)\n",
    "reduced_test_dataset = utilsTFG.reduce_dataset(test_dataset, 5000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.311338Z",
     "iopub.status.idle": "2024-09-24T19:59:37.311667Z",
     "shell.execute_reply": "2024-09-24T19:59:37.311501Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.311486Z"
    },
    "id": "bCwSZCjaVAYn",
    "outputId": "4a572271-b7a1-4baa-bb0c-a88d36d3c936"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Training set class distribution:\")\n",
    "utilsTFG.verify_class_balance(reduced_train_dataset)\n",
    "\n",
    "print(\"\\nTest set class distribution:\")\n",
    "utilsTFG.verify_class_balance(reduced_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.312623Z",
     "iopub.status.idle": "2024-09-24T19:59:37.312903Z",
     "shell.execute_reply": "2024-09-24T19:59:37.312778Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.312764Z"
    },
    "id": "7eJWaxGjWEkK",
    "outputId": "7f5eab93-2ec2-4b25-a65b-40c70195e787"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "valid_ratio=0.5\n",
    "# The size of the validation set is the same as the size of the test set\n",
    "validation_size = int(len(reduced_test_dataset)*valid_ratio)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_subset = reduced_train_dataset\n",
    "\n",
    "# Split the test dataset into validation and test subsets\n",
    "validation_subset, test_subset = random_split(reduced_test_dataset, [validation_size,len(reduced_test_dataset)-validation_size])\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 512\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check the size of each DataLoader\n",
    "print(f'Training set size: {len(train_loader.dataset)}')\n",
    "print(f'Validation set size: {len(validation_loader.dataset)}')\n",
    "print(f'Test set size: {len(test_loader.dataset)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.314956Z",
     "iopub.status.idle": "2024-09-24T19:59:37.315332Z",
     "shell.execute_reply": "2024-09-24T19:59:37.315200Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.315168Z"
    },
    "id": "RM7nRijOW9Rl",
    "outputId": "24475436-3ab4-41e4-94bf-6bd7ea512dc4"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "dls = DataLoaders.from_dsets(train_subset, validation_subset, bs=batch_size)\n",
    "test_dl = dls.test_dl(reduced_test_dataset)\n",
    "dls.to(device)\n",
    "test_dl.to(device)\n",
    "\n",
    "models =['LeNet5', 'ResNet15', 'ResNet57']\n",
    "mod = [utilsTFG.LeNet5(), utilsTFG.ResNet15(num_classes=10), utilsTFG.ResNet57(num_classes=10)]\n",
    "optims = ['NAG', 'RMSProp', 'ADAM']\n",
    "algs = ['SHADE', 'SHADE-ILS', 'SHADE-GD', 'SHADE-ILS-GD']\n",
    "metric = ['Acc']\n",
    "\n",
    "init_weights = {}\n",
    "for model, m in zip(models, mod):\n",
    "  learn = Learner(dls, model=copy.deepcopy(m), loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n",
    "  learn.model.apply(utilsTFG.init_weights_glorot)\n",
    "  learn.to(device)\n",
    "  init_weights[model] = utilsTFG.get_params_from_model(learn.model)\n",
    "  print(learn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.316544Z",
     "iopub.status.idle": "2024-09-24T19:59:37.316810Z",
     "shell.execute_reply": "2024-09-24T19:59:37.316694Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.316680Z"
    },
    "id": "-MrFvuJjnKAI",
    "outputId": "c31fdab0-5544-4d1f-e995-51ce0ae79ded"
   },
   "outputs": [],
   "source": [
    "# Get a batch of images and labels\n",
    "batch = dls.one_batch()\n",
    "\n",
    "# Number of images to display\n",
    "num_images = 10\n",
    "\n",
    "# Create a figure with a grid of subplots (2 rows and 4 columns)\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n",
    "\n",
    "# Plot each image in the grid\n",
    "for i in range(num_images):\n",
    "    row, col = divmod(i, 5)\n",
    "    ax = axes[row, col]\n",
    "    img = batch[0][i].cpu().squeeze().numpy()\n",
    "    label = class_names[batch[1][i].item()]\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(label)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAXMJnW_5Mpe"
   },
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.317694Z",
     "iopub.status.idle": "2024-09-24T19:59:37.317981Z",
     "shell.execute_reply": "2024-09-24T19:59:37.317851Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.317836Z"
    },
    "id": "zQ8UaExBxOtJ"
   },
   "outputs": [],
   "source": [
    "# Define the optimizers\n",
    "NAG = partial(OptimWrapper, opt=torch.optim.SGD, momentum=0.9, nesterov=True)\n",
    "RMSProp = partial(OptimWrapper, opt=torch.optim.RMSprop)\n",
    "ADAM = partial(OptimWrapper, opt=torch.optim.Adam)\n",
    "optims2 = [NAG, RMSProp, ADAM]\n",
    "\n",
    "# Initialize the learners dictionary\n",
    "learners = {}\n",
    "time_gd = {}\n",
    "epochs=20\n",
    "\n",
    "# Iterate over the optimizers and layers to create learners\n",
    "for opt, opt2 in zip(optims, optims2):\n",
    "    learners[opt] = {}  # Initialize the dictionary for this optimizer\n",
    "    time_gd[opt] = {}\n",
    "    for model, m in zip(models,mod):\n",
    "        learners[opt][model] = Learner(dls=dls, model=copy.deepcopy(m), loss_func=CrossEntropyLossFlat(), metrics=accuracy, opt_func=opt2, cbs=[SaveModelCallback()])\n",
    "        learners[opt][model].to(device)\n",
    "        learners[opt][model].model.to(device)\n",
    "        utilsTFG.set_params_to_model(init_weights[model], learners[opt][model].model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.318898Z",
     "iopub.status.idle": "2024-09-24T19:59:37.319207Z",
     "shell.execute_reply": "2024-09-24T19:59:37.319055Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.319040Z"
    },
    "id": "LPKLUItNTqY6",
    "outputId": "4092c1c4-c567-4024-bb17-abbce8af2190"
   },
   "outputs": [],
   "source": [
    "#To check if the models have the same initial parameters\n",
    "for model in models:\n",
    "  if utilsTFG.compare_models(learners['NAG'][model], learners['RMSProp'][model]) and utilsTFG.compare_models(learners['NAG'][model], learners['ADAM'][model]) and utilsTFG.compare_models(learners['ADAM'][model], learners['RMSProp'][model]):\n",
    "    print(f\"Mismos parámetros con el modelo {model}.\")\n",
    "  else:\n",
    "    print(\"Distintos parámetros.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xf4SSlxi5jJn"
   },
   "source": [
    "### Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.320076Z",
     "iopub.status.idle": "2024-09-24T19:59:37.320430Z",
     "shell.execute_reply": "2024-09-24T19:59:37.320274Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.320259Z"
    },
    "id": "vwND1SY51Dku",
    "outputId": "4e1d71c9-7d1b-41ce-f4b4-89ebaf7a241e"
   },
   "outputs": [],
   "source": [
    "#Run the training and measure the time for each layer\n",
    "for model, learner in learners['NAG'].items():\n",
    "  lr=learner.lr_find()\n",
    "  start = time.perf_counter()\n",
    "  learner.fit_one_cycle(epochs, lr)\n",
    "  end = time.perf_counter()\n",
    "  time_gd['NAG'][model] = end-start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.321249Z",
     "iopub.status.idle": "2024-09-24T19:59:37.321590Z",
     "shell.execute_reply": "2024-09-24T19:59:37.321414Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.321400Z"
    },
    "id": "eU7WXrz65YsN",
    "outputId": "4abca112-6c5d-4b3f-fb14-497a85287cfe"
   },
   "outputs": [],
   "source": [
    "#Plot the grafic for all layers combined\n",
    "utilsTFG.plot_learners_training(learners['NAG'].values(), title=f'{plot_dataset} WITH NAG OPTIMIZER', names=models, metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9XuoiwK5lnb"
   },
   "source": [
    "### RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.322550Z",
     "iopub.status.idle": "2024-09-24T19:59:37.322853Z",
     "shell.execute_reply": "2024-09-24T19:59:37.322704Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.322690Z"
    },
    "id": "BmMwFUjDCfDF",
    "outputId": "4f7cee1f-b99a-44a2-9511-5c14051472a0"
   },
   "outputs": [],
   "source": [
    "#Run the training and measure the time for each layer\n",
    "for model, learner in learners['RMSProp'].items():\n",
    "  lr=learner.lr_find()\n",
    "  start = time.perf_counter()\n",
    "  learner.fit_one_cycle(epochs, lr)\n",
    "  end = time.perf_counter()\n",
    "  time_gd['RMSProp'][model] = end-start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.323847Z",
     "iopub.status.idle": "2024-09-24T19:59:37.324140Z",
     "shell.execute_reply": "2024-09-24T19:59:37.324015Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.324000Z"
    },
    "id": "FHfcq1cJChpy",
    "outputId": "bc640a6b-48cc-49b5-c898-123282ec3bca"
   },
   "outputs": [],
   "source": [
    "#Plot the grafic for all layers combined\n",
    "utilsTFG.plot_learners_training(learners['RMSProp'].values(), title=f'{plot_dataset} WITH RMSProp OPTIMIZER', names=models, metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXiJLlKn53-5"
   },
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.325071Z",
     "iopub.status.idle": "2024-09-24T19:59:37.325493Z",
     "shell.execute_reply": "2024-09-24T19:59:37.325294Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.325273Z"
    },
    "id": "jyyhphXSCpbc",
    "outputId": "0f768eea-c99f-48a2-bdbd-cbd68c6c680c"
   },
   "outputs": [],
   "source": [
    "#Run the training and measure the time for each layer\n",
    "for model, learner in learners['ADAM'].items():\n",
    "  try:\n",
    "    lr=learner.lr_find()\n",
    "  except:\n",
    "    lr=0.01\n",
    "  start = time.perf_counter()\n",
    "  learner.fit_one_cycle(epochs, lr)\n",
    "  end = time.perf_counter()\n",
    "  time_gd['ADAM'][model] = end-start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.327123Z",
     "iopub.status.idle": "2024-09-24T19:59:37.327446Z",
     "shell.execute_reply": "2024-09-24T19:59:37.327308Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.327287Z"
    },
    "id": "pPYFbofVCrFI",
    "outputId": "46ab9b01-3d26-443f-eac5-683e1ad3eef3"
   },
   "outputs": [],
   "source": [
    "#Plot the grafic for all layers combined\n",
    "utilsTFG.plot_learners_training(learners['ADAM'].values(), title=f'{plot_dataset} WITH ADAM OPTIMIZER', lim=2, names=models, metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDJ8eghf-Z7b"
   },
   "source": [
    "### Save or Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.328131Z",
     "iopub.status.idle": "2024-09-24T19:59:37.328397Z",
     "shell.execute_reply": "2024-09-24T19:59:37.328277Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.328263Z"
    },
    "id": "-fBPMqJnioAO"
   },
   "outputs": [],
   "source": [
    "#Save learner with their losses and metrics\n",
    "for optim in optims:\n",
    "  for model in models:\n",
    "    file_path = f'/notebooks/saved_models/learner_{dataset}_{model}_{optim}.pkl'\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump({'learner': learners[optim][model], 'recorder_values': learners[optim][model].recorder.values}, f)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.329188Z",
     "iopub.status.idle": "2024-09-24T19:59:37.329514Z",
     "shell.execute_reply": "2024-09-24T19:59:37.329378Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.329358Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = f'/notebooks/saved_models/learner_times_{datset}.pkl'\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(time_gd, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.330319Z",
     "iopub.status.idle": "2024-09-24T19:59:37.330593Z",
     "shell.execute_reply": "2024-09-24T19:59:37.330472Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.330458Z"
    },
    "id": "KLtzsDrDiwg6",
    "outputId": "4fb00027-dacd-4383-85c4-a0b05afb908e"
   },
   "outputs": [],
   "source": [
    "#Load learner with their losses and metrics\n",
    "for optim in optims:\n",
    "  for models in models:\n",
    "    file_path = f'/notebooks/saved_models/learner_{dataset}_{model}_{optim}.pkl'\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    learners[optim][model], learners[optim][model].recorder.values = data['learner'], data['recorder_values']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSZOLyrzCx-H"
   },
   "source": [
    "### Comparative per models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.331346Z",
     "iopub.status.idle": "2024-09-24T19:59:37.331680Z",
     "shell.execute_reply": "2024-09-24T19:59:37.331546Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.331529Z"
    },
    "id": "Dm1S4bJKC1l4",
    "outputId": "9ba2bbd9-9fff-44f7-c102-1f69cd900d86"
   },
   "outputs": [],
   "source": [
    "#Compare the three optimizers for each layer\n",
    "\n",
    "learners_lenet =[learners['NAG']['LeNet5'], learners['RMSProp']['LeNet5'], learners['ADAM']['LeNet5']]\n",
    "learners_resnet = [learners['NAG']['ResNet15'], learners['RMSProp']['ResNet15'], learners['ADAM']['ResNet15']]\n",
    "learners_resnet57 = [learners['NAG']['ResNet57'], learners['RMSProp']['ResNet57'], learners['ADAM']['ResNet57']]\n",
    "\n",
    "names=['NAG', 'RMSProp', 'ADAM']\n",
    "utilsTFG.plot_learners_training(learners_lenet, title=f'{plot_dataset} WITH LeNet5', names=names, metric=metric)\n",
    "utilsTFG.plot_learners_training(learners_resnet, title=f'{plot_dataset} WITH ResNet15', names=names, metric=metric)\n",
    "utilsTFG.plot_learners_training(learners_resnet57, title=f'{plot_dataset} WITH ResNet57', names=names, metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nW6XoO5AHeNx"
   },
   "source": [
    "### Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkD7d34jVqJG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.332410Z",
     "iopub.status.idle": "2024-09-24T19:59:37.332663Z",
     "shell.execute_reply": "2024-09-24T19:59:37.332549Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.332536Z"
    },
    "id": "hyFE2uCjOL21",
    "outputId": "92bdfb74-1594-435d-956f-aaa8fa96bc7e"
   },
   "outputs": [],
   "source": [
    "models =['LeNet5', 'ResNet15'] #Sometimes it overrides the array\n",
    "#Run the model in the test set\n",
    "for optim in optims:\n",
    "  for model in models:\n",
    "    #Run the model with optimizer optim and n_layers layer the test set in evaluation mode\n",
    "    learners[optim][model].model.eval()\n",
    "    learners[optim][model].eval()\n",
    "    preds, targs = learners[optim][model].get_preds(dl=test_dl)\n",
    "    targs = targs.long().squeeze()\n",
    "\n",
    "    # Calculate bal_accuracy\n",
    "    accuracy = utilsTFG.balanced_accuracy_func(preds, targs)\n",
    "\n",
    "    #Calculate loss\n",
    "    loss = utilsTFG.err_param_w_model(learners[optim][model].model, test_dl, mode = 'test')\n",
    "    #loss = CrossEntropyLossFlat()(preds, targs)\n",
    "\n",
    "\n",
    "    print(f\"Optimizer: {optim}, Model: {model}, Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uqQJyG75Sgy"
   },
   "source": [
    "## Metaheuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.333563Z",
     "iopub.status.idle": "2024-09-24T19:59:37.333839Z",
     "shell.execute_reply": "2024-09-24T19:59:37.333724Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.333711Z"
    },
    "id": "jJu55Krnr-77"
   },
   "outputs": [],
   "source": [
    "#Initialise dictionaries\n",
    "pop_size=10\n",
    "population = {}\n",
    "fitness = {}\n",
    "mh_learners = {}\n",
    "results = {}\n",
    "fitness_valid = {}\n",
    "best = {}\n",
    "time_mh = {}\n",
    "\n",
    "#Initialise the population to have the same values for all the MH\n",
    "for model,m in zip(models,mod):\n",
    "  population[model] = []\n",
    "  fitness[model] = []\n",
    "  mh_learners[model] = Learner(dls, model=copy.deepcopy(m), loss_func=CrossEntropyLossFlat(),  cbs=[SaveModelCallback()], opt_func=optim)\n",
    "  mh_learners[model].to(device)\n",
    "  mh_learners[model].model.to(device)\n",
    "  for _ in range(pop_size):\n",
    "    model_copy = copy.deepcopy(mh_learners[model].model)\n",
    "\n",
    "    # Reset the weights of the model copy\n",
    "    model_copy.apply(utilsTFG.init_weights_glorot)\n",
    "\n",
    "    # Add the reinitialized model to the population list\n",
    "    population[model].append(utilsTFG.get_params_from_model(model_copy))\n",
    "\n",
    "    fitness[model].append(utilsTFG.err_param_w_model(model_copy, dls))\n",
    "\n",
    "#More initialisation\n",
    "for alg in algs:\n",
    "  results[alg] = {}\n",
    "  fitness_valid[alg] = {}\n",
    "  best[alg] = {}\n",
    "  time_mh[alg] = {}\n",
    "\n",
    "max_evals=4200\n",
    "max_evals_shade=200\n",
    "max_ls=10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "II8zvBWa5rRq"
   },
   "source": [
    "### Genetic Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.334591Z",
     "iopub.status.idle": "2024-09-24T19:59:37.334834Z",
     "shell.execute_reply": "2024-09-24T19:59:37.334721Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.334708Z"
    },
    "id": "ROV0Y5Drp8e0"
   },
   "outputs": [],
   "source": [
    "#Genetic Algorithm working as supposed to (terrible performance)\n",
    "#results['GA'] = {}\n",
    "#for layer in n_layers:\n",
    "#  start = time.perf_counter()\n",
    "#  results['GA'][layer] = utilsTFG.gen_alg(pop_size, copy.deepcopy(population[layer]), fitness[layer], dls, 4000, mh_learners[layer])\n",
    "#  end = time.perf_counter()\n",
    "#  time_mh['GA'][layer] = end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpJIxWTta8ZH"
   },
   "source": [
    "### SHADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.335743Z",
     "iopub.status.idle": "2024-09-24T19:59:37.336017Z",
     "shell.execute_reply": "2024-09-24T19:59:37.335905Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.335891Z"
    },
    "id": "C_-CGNmxz47L"
   },
   "outputs": [],
   "source": [
    "#Runing SHADE algorithm\n",
    "\n",
    "results['SHADE'] = {}\n",
    "for model in models:\n",
    "  start = time.perf_counter()\n",
    "  results['SHADE'][model] = utilsTFG.SHADE_ej(copy.deepcopy(population[model]), copy.deepcopy(fitness[model]), pop_size,max_evals, len(population[model][0]), dls,  model=mh_learners[model].model)\n",
    "  end = time.perf_counter()\n",
    "  time_mh['SHADE'][model] = end-start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.337028Z",
     "iopub.status.idle": "2024-09-24T19:59:37.337297Z",
     "shell.execute_reply": "2024-09-24T19:59:37.337178Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.337164Z"
    },
    "id": "IZXpBjr8_Ebo"
   },
   "outputs": [],
   "source": [
    "#Validate the models obtained.\n",
    "fitness_valid['SHADE'] = {}\n",
    "for model in models:\n",
    "  fitness_valid['SHADE'][model] = []\n",
    "  for ind in results['SHADE'][model][5]:\n",
    "    fitness_valid['SHADE'][model].append(utilsTFG.err_param_valid(ind, mh_learners[model].model, dls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.338260Z",
     "iopub.status.idle": "2024-09-24T19:59:37.338543Z",
     "shell.execute_reply": "2024-09-24T19:59:37.338412Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.338398Z"
    },
    "id": "ImL7pZG4BFMw",
    "outputId": "a386ee0a-7867-4950-d891-7d4d490c69e0"
   },
   "outputs": [],
   "source": [
    "#compare train and valid and select the best generalizing model.\n",
    "for model in models:\n",
    "  print(f\"Training error of SHADE for {model} model: {results['SHADE'][model][6]}\")\n",
    "  print(f\"Validation error of SHADE for {model} model: {fitness_valid['SHADE'][model]}\")\n",
    "  dif = np.array(fitness_valid['SHADE'][model]) - np.array(results['SHADE'][model][6])\n",
    "  print(f\"Difference: {dif}\")\n",
    "  mejor = np.argmin(fitness_valid['SHADE'][model])\n",
    "  best['SHADE'][model] = results['SHADE'][model][5][mejor]\n",
    "  print(f\"Best generalizing model: Model {mejor+1} (1-10)\")\n",
    "\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.339272Z",
     "iopub.status.idle": "2024-09-24T19:59:37.339538Z",
     "shell.execute_reply": "2024-09-24T19:59:37.339419Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.339405Z"
    }
   },
   "outputs": [],
   "source": [
    "#Save the mh results\n",
    "file_path = f'/notebooks/saved_models/SHADE_dict_{dataset}.pkl'\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(results['SHADE'], f)\n",
    "    \n",
    "#Save the mh results\n",
    "file_path = f'/notebooks/saved_models/SHADE_time_{dataset}.pkl'\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(time_mh['SHADE'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asIlfuQ45x1f"
   },
   "source": [
    "### SHADE-ILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.340277Z",
     "iopub.status.idle": "2024-09-24T19:59:37.340571Z",
     "shell.execute_reply": "2024-09-24T19:59:37.340437Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.340420Z"
    },
    "id": "6jU8lb4vzy3i"
   },
   "outputs": [],
   "source": [
    "# Running SHADE-ILS algorithm\n",
    "results['SHADE-ILS'] = {}\n",
    "for model in models:\n",
    "  start = time.perf_counter()\n",
    "  results['SHADE-ILS'][model] = utilsTFG.SHADE_ILS(copy.deepcopy(population[model]), copy.deepcopy(fitness[model]), max_evals, max_evals_shade, dls, mh_learners[model], mh_learners[model].model, max_ls=max_ls)\n",
    "  end = time.perf_counter()\n",
    "  time_mh['SHADE-ILS'][model] = end-start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.341331Z",
     "iopub.status.idle": "2024-09-24T19:59:37.341609Z",
     "shell.execute_reply": "2024-09-24T19:59:37.341488Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.341474Z"
    },
    "id": "U-gOpjgHDMxX"
   },
   "outputs": [],
   "source": [
    "#Validation error\n",
    "fitness_valid['SHADE-ILS'] = {}\n",
    "for model in models:\n",
    "  fitness_valid['SHADE-ILS'][model] = []\n",
    "  for ind in results['SHADE-ILS'][model][3]:\n",
    "    fitness_valid['SHADE-ILS'][model].append(utilsTFG.err_param_valid(ind, mh_learners[model].model, dls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.342492Z",
     "iopub.status.idle": "2024-09-24T19:59:37.342799Z",
     "shell.execute_reply": "2024-09-24T19:59:37.342675Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.342660Z"
    },
    "id": "TESZRYDzD2LM",
    "outputId": "3d56852b-c0fe-47b7-9303-f49d5b5e568a"
   },
   "outputs": [],
   "source": [
    "#Compare train and valid\n",
    "for model in models:\n",
    "  print(f\"Training error of SHADE-ILS for {model} model: {results['SHADE-ILS'][model][2]}\")\n",
    "  print(f\"Validation error of SHADE-ILS for {model} model: {fitness_valid['SHADE-ILS'][model]}\")\n",
    "  dif = np.array(fitness_valid['SHADE-ILS'][model]) - np.array(results['SHADE-ILS'][model][2])\n",
    "  print(f\"Difference: {dif}\")\n",
    "  mejor = np.argmin(fitness_valid['SHADE-ILS'][model])\n",
    "  best['SHADE-ILS'][model] = results['SHADE-ILS'][model][3][mejor]\n",
    "  print(f\"Best generalizing model: Model {mejor+1} (1-10)\")\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.343777Z",
     "iopub.status.idle": "2024-09-24T19:59:37.344054Z",
     "shell.execute_reply": "2024-09-24T19:59:37.343928Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.343914Z"
    }
   },
   "outputs": [],
   "source": [
    "#Save the mh results\n",
    "file_path = f'/notebooks/saved_models/SHADE-ILS_dict_{dataset}.pkl'\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(results['SHADE-ILS'], f)\n",
    "    \n",
    "#Save the mh results\n",
    "file_path = f'/notebooks/saved_models/SHADE-ILS_time_{dataset}.pkl'\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(time_mh['SHADE-ILS'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OauiNqFE04d"
   },
   "source": [
    "### SHADE-GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.344982Z",
     "iopub.status.idle": "2024-09-24T19:59:37.345261Z",
     "shell.execute_reply": "2024-09-24T19:59:37.345136Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.345122Z"
    },
    "id": "WLRnFTwIE3xf"
   },
   "outputs": [],
   "source": [
    "# Running SHADE algorithm with GD\n",
    "results['SHADE-GD'] = {}\n",
    "for model in models:\n",
    "  start = time.perf_counter()\n",
    "  results['SHADE-GD'][model] = utilsTFG.SHADE_GD(copy.deepcopy(population[model]), copy.deepcopy(fitness[model]), max_evals, max_evals_shade, dls, mh_learners[model], mh_learners[model].model)\n",
    "  end = time.perf_counter()\n",
    "  time_mh['SHADE-GD'][model] = end-start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.345949Z",
     "iopub.status.idle": "2024-09-24T19:59:37.346246Z",
     "shell.execute_reply": "2024-09-24T19:59:37.346099Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.346085Z"
    },
    "id": "IrbO5eVsFMCH"
   },
   "outputs": [],
   "source": [
    "#Validation error\n",
    "fitness_valid['SHADE-GD'] = {}\n",
    "for model in models:\n",
    "  fitness_valid['SHADE-GD'][model] = []\n",
    "  for ind in results['SHADE-GD'][model][3]:\n",
    "    fitness_valid['SHADE-GD'][model].append(utilsTFG.err_param_valid(ind, mh_learners[model].model, dls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.346990Z",
     "iopub.status.idle": "2024-09-24T19:59:37.347261Z",
     "shell.execute_reply": "2024-09-24T19:59:37.347142Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.347127Z"
    },
    "id": "kGaDgqrtFjfr",
    "outputId": "36611a9c-97c7-4b64-969d-2fbb7b8f63da"
   },
   "outputs": [],
   "source": [
    "#Compare train and valid\n",
    "for model in models:\n",
    "  print(f\"Training error of SHADE-GD for {model} model: {results['SHADE-GD'][model][2]}\")\n",
    "  print(f\"Validation error of SHADE-GD for {model} model: {fitness_valid['SHADE-GD'][model]}\")\n",
    "  dif = np.array(fitness_valid['SHADE-GD'][model]) - np.array(results['SHADE-GD'][model][2])\n",
    "  print(f\"Difference: {dif}\")\n",
    "  #mejor = np.argmin(dif)\n",
    "  mejor = np.argmin(fitness_valid['SHADE-GD'][model])\n",
    "  best['SHADE-GD'][model] = results['SHADE-GD'][model][3][mejor]\n",
    "  print(f\"Best generalizing model: Model {mejor+1} (1-10)\")\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.348148Z",
     "iopub.status.idle": "2024-09-24T19:59:37.348423Z",
     "shell.execute_reply": "2024-09-24T19:59:37.348300Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.348285Z"
    }
   },
   "outputs": [],
   "source": [
    "#Save the mh results\n",
    "file_path = f'/notebooks/saved_models/SHADE-GD_dict_{dataset}.pkl'\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(results['SHADE-GD'], f)\n",
    "    \n",
    "#Save the mh results\n",
    "file_path = f'/notebooks/saved_models/SHADE-GD_time_{dataset}.pkl'\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(time_mh['SHADE-GD'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yywEcrvtFcjJ"
   },
   "source": [
    "### SHADE-ILS-GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.349335Z",
     "iopub.status.idle": "2024-09-24T19:59:37.349612Z",
     "shell.execute_reply": "2024-09-24T19:59:37.349490Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.349475Z"
    },
    "id": "T9TnKFrWFyyV",
    "outputId": "50590812-92c7-4225-fa3a-75e90c65e0a7"
   },
   "outputs": [],
   "source": [
    "# SHADE-ILS-GD\n",
    "results['SHADE-ILS-GD'] = {}\n",
    "for model in models:\n",
    "  start = time.perf_counter()\n",
    "  results['SHADE-ILS-GD'][model] = utilsTFG.SHADE_ILS_GD(copy.deepcopy(population[model]), copy.deepcopy(fitness[model]),  max_evals, max_evals_shade, dls, mh_learners[model], mh_learners[model].model, max_ls=max_ls)\n",
    "  end = time.perf_counter()\n",
    "  time_mh['SHADE-ILS-GD'][model] = end-start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.350510Z",
     "iopub.status.idle": "2024-09-24T19:59:37.350772Z",
     "shell.execute_reply": "2024-09-24T19:59:37.350651Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.350637Z"
    },
    "id": "yuUZ4JqVF6M6"
   },
   "outputs": [],
   "source": [
    "#Validation error\n",
    "fitness_valid['SHADE-ILS-GD'] = {}\n",
    "for model in models:\n",
    "  fitness_valid['SHADE-ILS-GD'][model] = []\n",
    "  for ind in results['SHADE-ILS-GD'][model][3]:\n",
    "    fitness_valid['SHADE-ILS-GD'][model].append(utilsTFG.err_param_valid(ind, mh_learners[model].model, dls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.351564Z",
     "iopub.status.idle": "2024-09-24T19:59:37.351840Z",
     "shell.execute_reply": "2024-09-24T19:59:37.351720Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.351706Z"
    },
    "id": "qlR3uvC2FQT7",
    "outputId": "d5e2bbc0-57ba-47d7-a702-680ff94c59f2"
   },
   "outputs": [],
   "source": [
    "#Compare train and valid\n",
    "for model in models:\n",
    "  print(f\"Training error of SHADE-ILS-GD for {model} model: {results['SHADE-ILS-GD'][model][2]}\")\n",
    "  print(f\"Validation error of SHADE-ILS-GD for {model} model: {fitness_valid['SHADE-ILS-GD'][model]}\")\n",
    "  dif = np.array(fitness_valid['SHADE-ILS-GD'][model]) - np.array(results['SHADE-ILS-GD'][model][2])\n",
    "  print(f\"Difference: {dif}\")\n",
    "  mejor = np.argmin(fitness_valid['SHADE-ILS-GD'][model])\n",
    "  best['SHADE-ILS-GD'][model] = results['SHADE-ILS-GD'][model][3][mejor]\n",
    "  print(f\"Best generalizing model: Model {mejor+1} (1-10)\")\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.352738Z",
     "iopub.status.idle": "2024-09-24T19:59:37.353010Z",
     "shell.execute_reply": "2024-09-24T19:59:37.352888Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.352874Z"
    }
   },
   "outputs": [],
   "source": [
    "#Save the mh results\n",
    "file_path = f'/notebooks/saved_models/SHADE-ILS-GD_dict_{dataset}.pkl'\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(results['SHADE-ILS-GD'], f)\n",
    "    \n",
    "#Save the mh results\n",
    "file_path = f'/notebooks/saved_models/SHADE-ILS-GD_time_{dataset}.pkl'\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(time_mh['SHADE-ILS-GD'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save or load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.353876Z",
     "iopub.status.idle": "2024-09-24T19:59:37.354184Z",
     "shell.execute_reply": "2024-09-24T19:59:37.354024Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.354010Z"
    },
    "id": "gA_N1kGA7Ndn"
   },
   "outputs": [],
   "source": [
    "#Save the mh results\n",
    "file_path = f'/notebooks/saved_models/mh_dict_{dataset}.pkl'\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.355238Z",
     "iopub.status.idle": "2024-09-24T19:59:37.355517Z",
     "shell.execute_reply": "2024-09-24T19:59:37.355391Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.355377Z"
    },
    "id": "AzIkgJvH7VUX"
   },
   "outputs": [],
   "source": [
    "#Load the trained mh results\n",
    "file_path = f'/notebooks/saved_models/mh_dict_{dataset}.pkl'\n",
    "with open(file_path, 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gQs5Loyjstj"
   },
   "source": [
    "### Comparison between MH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.356215Z",
     "iopub.status.idle": "2024-09-24T19:59:37.356483Z",
     "shell.execute_reply": "2024-09-24T19:59:37.356364Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.356350Z"
    },
    "id": "LL-t9M9UjscC"
   },
   "outputs": [],
   "source": [
    "#Saving training loss for better manipulation\n",
    "training = {}\n",
    "for mh in algs:\n",
    "  training[mh] = {}\n",
    "for model in models:\n",
    "  training['SHADE'][model] = results['SHADE'][model][6]\n",
    "  training['SHADE-ILS'][model] = results['SHADE-ILS'][model][2]\n",
    "  training['SHADE-GD'][model] = results['SHADE-GD'][model][2]\n",
    "  training['SHADE-ILS-GD'][model] = results['SHADE-ILS-GD'][model][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.357346Z",
     "iopub.status.idle": "2024-09-24T19:59:37.357618Z",
     "shell.execute_reply": "2024-09-24T19:59:37.357497Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.357483Z"
    },
    "id": "YMC78-iKkrXw",
    "outputId": "d2d62cd1-74e6-4e78-a345-9d1697bcca5a"
   },
   "outputs": [],
   "source": [
    "from fastai.metrics import accuracy\n",
    "#Calculate accuracy and accuracy\n",
    "acc = {}\n",
    "for mh in algs:\n",
    "  acc[mh] = {}\n",
    "  for model in models:\n",
    "    acc[mh][model] = []\n",
    "    ind = 5 if mh == 'SHADE' else 3\n",
    "    for ind in results[mh][model][ind]:\n",
    "      utilsTFG.set_params_to_model(ind, mh_learners[model].model)\n",
    "      mh_learners[model].model.eval()\n",
    "      mh_learners[model].eval()\n",
    "      preds, targs = mh_learners[model].get_preds(dl=dls.valid)\n",
    "      targs = targs.long().squeeze()\n",
    "\n",
    "      # Calculate balanced_accuracy\n",
    "      acc[mh][model].append(accuracy(preds, targs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.358656Z",
     "iopub.status.idle": "2024-09-24T19:59:37.358929Z",
     "shell.execute_reply": "2024-09-24T19:59:37.358807Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.358793Z"
    },
    "id": "oCU9LIgBn3d6",
    "outputId": "61a80b9e-eaef-49ed-b48b-2e07575ba39d"
   },
   "outputs": [],
   "source": [
    "#Comparing the different layers version of the same MH\n",
    "for alg in algs:\n",
    "  utilsTFG.plot_mh_mlp_training(training[alg], fitness_valid[alg], acc[alg], layers=models, names=models, title=f'TRAINING IN {plot_dataset} WITH {alg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 922
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.359814Z",
     "iopub.status.idle": "2024-09-24T19:59:37.360154Z",
     "shell.execute_reply": "2024-09-24T19:59:37.360027Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.360012Z"
    },
    "id": "mRZSN99ByO-E",
    "outputId": "79857249-7825-49c8-b594-21fe8cd2a0cd"
   },
   "outputs": [],
   "source": [
    "#Comparing the different MH for the same layer number\n",
    "\n",
    "names= ['SHADE', 'SHADE-ILS', 'SHADE-GD', 'SHADE-ILS-GD']\n",
    "train = {}\n",
    "ac = {}\n",
    "valid = {}\n",
    "for model in models:\n",
    "  train[model] = {}\n",
    "  ac[model] = {}\n",
    "  valid[model] = {}\n",
    "  for alg in algs:\n",
    "    train[model][alg] = training[alg][model]\n",
    "    ac[model][alg] = acc[alg][model]\n",
    "    valid[model][alg] = fitness_valid[alg][model]\n",
    "  utilsTFG.plot_mh_mlp_training(train[model], valid[model], ac[model],  layers=names, names=names, title=f'TRAINING IN {plot_dataset} WITH {model}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCsn1tMYzDKZ"
   },
   "source": [
    "### Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.361038Z",
     "iopub.status.idle": "2024-09-24T19:59:37.361310Z",
     "shell.execute_reply": "2024-09-24T19:59:37.361190Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.361175Z"
    },
    "id": "zs9RTlG8y4FN",
    "outputId": "d4933e67-1fed-4b05-d233-88222cce2717"
   },
   "outputs": [],
   "source": [
    "#Run the model in the test set\n",
    "for mh in algs:\n",
    "  for model in models:\n",
    "    #Run the model with optimizer optim and n_layers layer the test set in evaluation mode\n",
    "    utilsTFG.set_params_to_model(best[mh][model], mh_learners[model].model)\n",
    "    mh_learners[model].model.eval()\n",
    "    mh_learners[model].eval()\n",
    "    preds, targs = mh_learners[model].get_preds(dl=test_dl)\n",
    "    targs = targs.long().squeeze()\n",
    "\n",
    "    #Calculate accuracy\n",
    "\n",
    "    accur = utilsTFG.balanced_accuracy_func(preds, targs)\n",
    "\n",
    "\n",
    "    loss = utilsTFG.err_param_w_model(mh_learners[model].model, test_dl, mode = 'test')\n",
    "\n",
    "    print(f\"Optimizer: {mh}, Model: {model}, Loss: {loss}, Accuracy: {accur}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLTkRRlSs22N"
   },
   "source": [
    "## Time comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-24T19:59:37.362265Z",
     "iopub.status.idle": "2024-09-24T19:59:37.362537Z",
     "shell.execute_reply": "2024-09-24T19:59:37.362422Z",
     "shell.execute_reply.started": "2024-09-24T19:59:37.362409Z"
    },
    "id": "-V5rkuQrs4xl",
    "outputId": "b0a2fac6-1225-4527-aee9-1855aba0dd81"
   },
   "outputs": [],
   "source": [
    "#Compare times for each algorithm and layer\n",
    "\n",
    "#GD\n",
    "for alg, time_model in time_mh.items():\n",
    "  for model, time in time_model.items():\n",
    "    print(f'Time consumed by {alg} training with {model}: {time:.04f} seconds')\n",
    "\n",
    "#MH\n",
    "for optims, time_model in time_gd.items():\n",
    "  for model, time in time_model.items():\n",
    "    print(f'Time consumed by {optims} training with {model}: {time:.04f} seconds')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "P9XuoiwK5lnb",
    "AXiJLlKn53-5",
    "rDJ8eghf-Z7b",
    "lSZOLyrzCx-H",
    "nW6XoO5AHeNx"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
